---
title: "xxx"
author: "Group 09"
number-sections: true
format: 
  html:
    embed-resources: true
    code-tools: true
  pdf:
    geometry: "left=2cm, right=2cm, top=2cm, bottom=2cm"
editor_options: 
  chunk_output_type: inline
execute:
  echo: false
  eval: true
  warning: false
  message: false
---

```{r}
library(ggplot2)
library(tidyverse)
library(skimr)
library(moderndive)
library(gapminder)
library(sjPlot)
library(stats)
library(jtools)
library(kableExtra)
```

## Introduction

The following analysis aims to understand the relationship between a set of descriptive variables about a film and its success measured by its respective IMDB rating.

The central question around this analysis will be the following: **Which properties of films influence whether they are rated by IMDB as greater than 7 or not?**

From this question it is established that the target variable will be binary and hence a Logistic Regression model seems reasonable for this scenario. It is also established that missing variables ( in case they are found ) will be inputted with a summary statistic like mean or median if the distribution of this subset is similar to that of the complete data set, otherwise they will be deleted if they do not represent a large portion of the data set.

Throughout this analysis a full model will be fitted taking into account all numerical and categorical variables in the data set. Then the best performing model will be selected and it will only include those variables which are found to be significant.

Finally, a short summary of the model and answers to the analysis question will be found in the conclusion section.

## Data Cleaning

The film data set obtained from IMDB contains the following variables:

-   film.id - The unique identifier for the film

-   year - Year of release of the film in cinemas

-   length - Duration (in minutes)

-   budget - Budget for the films production (in \$1000000s)

-   votes - Number of positive votes received by viewers

-   genre - Genre of the film

-   rating - IMDB rating from 0-10

```{r}
#Read data set
film <- read.csv("dataset09.csv") %>% 
  mutate(target = ifelse(rating>7, 1, 0)) %>%  #Define target variable
  mutate(Rating = ifelse(rating>7, ">7", "<=7"))  #Define Rating variable help us get better data visualisation

#Create summary
film %>% 
  skim()
```

It is now established that film_id will not be used as an explanatory variable since it is only an identifier for the film, rather than an informative feature about it. Genre is the only categorical variable contained in the data set. Year, length, budget, and votes are the numerical explanatory variables to be tested in this analysis.

When it comes to the data set, there seems to be an issue with the length variable as there are 127 rows where this information is missing.

```{r}
#Find the missing value of length
film %>% 
  filter(is.na(length)) %>% 
  skim()
```

From the summary above it is easy to see that the distribution of these 127 rows is fairly similar to that of the complete data set ( This is made evident when comparing the histograms of the filtered data set to those of the complete data set ).

```{r}
#Group by genre and select the variables 'genre' and 'length'
film %>% 
  group_by(genre) %>%
  select(genre, length) %>%
  skim()
```

It is evident in from the summary table above that the length distribution is not equal amongst different film genres and therefore the missing film lengths will be handled by adding the median film length by genre to its corresponding missing columns (the mean is not used to avoid outlier influence). The different behaviour between genre and film length was expected, especially because one category is called "Short".

```{r}
#Median length of each genre
film.median <- film %>%
  group_by(genre) %>%
  select(genre, length) %>%
  summarise(median.length = median(length, na.rm=TRUE))
film.median
```

```{r}
#Input corresponding genre median for length missing values 
film <- film %>%
  inner_join(film.median,by=join_by(genre)) %>%
  mutate(had_NAS=ifelse(is.na(length),TRUE,FALSE),length=ifelse(is.na(length),median.length,length)) %>%
  select(-median.length) 
```

## Exploratory Analysis

The last step before fitting the Logistic Regression model is analysing the data set to identify possible patterns.

```{r}
#These are just some simple plots. Please add more plots as necessary. 
#If a certain plot is needed in the power point presentation please write its code here. 
```

```{r}
#| echo: true
#| label: fig-boxplot_1
#| fig-cap: Boxplot of Year by Rating
#| fig-width: 8
#| fig-height: 5
#| fig-align: center

#Plot target variable against year covariate 
film %>% ggplot(aes(x=Rating, y=year, colour=Rating)) + 
  geom_boxplot() + 
  theme(legend.position="none") +
  labs(x="Rating", y="Year")
```

```{r}
#| echo: true
#| label: fig-boxplot_2
#| fig-cap: Boxplot of Length by Rating
#| fig-width: 8
#| fig-height: 5
#| fig-align: center

#Plot target variable against length covariate 
film %>% ggplot(aes(x=Rating, y=length, colour=Rating)) + 
  geom_boxplot() + 
  theme(legend.position="none") +
  labs(x="Rating", y="Length")
```

```{r}
#| echo: true
#| label: fig-boxplot_3
#| fig-cap: Boxplot of Budget by Rating
#| fig-width: 8
#| fig-height: 5
#| fig-align: center

#Plot target variable against budget covariate 
film %>% ggplot(aes(x=Rating, y=budget, colour=Rating)) + 
  geom_boxplot() + 
  theme(legend.position="none") +
  labs(x="Rating", y="Budget")
```

```{r}
#| echo: true
#| label: fig-boxplot_4
#| fig-cap: Boxplot of Votes by Rating
#| fig-width: 8
#| fig-height: 5
#| fig-align: center

#Plot target variable against votes covariate 
film %>% ggplot(aes(x=Rating, y=votes, colour=Rating)) + 
  geom_boxplot() + 
  theme(legend.position="none") +
  labs(x="Rating", y="Votes")
```

```{r}
#| echo: true
#| label: fig-barplot_1
#| fig-cap: Barplot of count by genre
#| fig-width: 8
#| fig-height: 5
#| fig-align: center

#Count by genre
film %>% 
  ggplot(aes(x=genre, colour=genre)) +
  geom_bar() +
  theme(legend.position="none") +
  labs(y="Count", x="Film genre")
```

```{r}
#| echo: true
#| label: fig-barplot_2
#| fig-cap: Proportion of films with rating >7 by genre
#| fig-width: 8
#| fig-height: 5
#| fig-align: center

#Proportion of films with rating >7 by genre
film %>% group_by(genre) %>% 
  summarise(prop = mean(target)) %>% 
  arrange() %>% 
  ggplot(aes(x=genre, y=prop, colour=genre)) +
  geom_col() +
  theme(legend.position="none") +
  labs(y="Proportion with rating > 7", x="Film genre")
```

## Model Fitting

```{r}
#Fit a full model with all possible covariates
model1 <- glm(target ~ year + length + budget + votes + genre , data = film, 
             family = binomial(link = "logit"))
model1 %>%
  summary()
```

The year the film was released is not significant in the model above. This is expected as the year a certain movie was released might not say much about its success on IMDB.

```{r}
#Fit without year, change votes to thousands so the scale is easier to interpret
model2 <- glm(target ~ length + budget + votes + genre , data = film %>%
                mutate(votes=votes/1000), family = binomial(link = "logit"))
model2 %>%
  summary()
```

```{r}
summ(model2)
```

```{r}
mod2coefs <- round(coef(model2), 3)
mod2coefs
```

```{r}
confint(model2) %>%
  kable()
```

```{r}
plot_model(model2., type = "pred", title = "",
            axis.title = c("Ethnicity", "Prob. of instructor being male"))
```

```{r}
film <- film %>% 
  mutate(probs=fitted(model2))
```

```{r}
#obtain the model equation and display it using latek to be able to determine which variables influence a film's success the most 
```

## Conclusion

```{r}
#Write a conclusion about which variables were non-significant, which were significant and how much they influence the probability of having a score >7
```



```{r}
library(ggplot2)
library(tidyverse)
library(skimr)
library(moderndive)
library(gapminder)
library(sjPlot)
library(stats)
library(jtools)
library(kableExtra)
library(caret)
library(pROC)
```

## Introduction

The following analysis aims to understand the relationship between a set of descriptive variables about a film and its success measured by its respective IMDB rating.

The central question around this analysis will be the following: **Which properties of films influence whether they are rated by IMDB as greater than 7 or not?**

From this question it is established that the target variable will be binary and hence a Logistic Regression model seems reasonable for this scenario. It is also established that missing variables ( in case they are found ) will be inputted with a summary statistic like mean or median if the distribution of this subset is similar to that of the complete data set, otherwise they will be deleted if they do not represent a large portion of the data set.

Throughout this analysis a full model will be fitted taking into account all numerical and categorical variables in the data set. Then the best performing model will be selected and it will only include those variables which are found to be significant.

Finally, a short summary of the model and answers to the analysis question will be found in the conclusion section.

## Data Cleaning

The film data set obtained from IMDB contains the following variables:

-   film.id - The unique identifier for the film

-   year - Year of release of the film in cinemas

-   length - Duration (in minutes)

-   budget - Budget for the films production (in \$1000000s)

-   votes - Number of positive votes received by viewers

-   genre - Genre of the film

-   rating - IMDB rating from 0-10

```{r}
#Read data set
film <- read.csv("dataset09.csv") %>% 
  mutate(target = ifelse(rating>7, 1, 0)) %>%  #Define target variable
  mutate(Rating = ifelse(rating>7, ">7", "<=7"))  #Define Rating variable help us get better data visualisation

#Create summary
film %>% 
  skim()
```

It is now established that film_id will not be used as an explanatory variable since it is only an identifier for the film, rather than an informative feature about it. Genre is the only categorical variable contained in the data set. Year, length, budget, and votes are the numerical explanatory variables to be tested in this analysis.

When it comes to the data set, there seems to be an issue with the length variable as there are 127 rows where this information is missing.

```{r}
#Find the missing value of length
film %>% 
  filter(is.na(length)) %>% 
  skim()
```

From the summary above it is easy to see that the distribution of these 127 rows is fairly similar to that of the complete data set ( This is made evident when comparing the histograms of the filtered data set to those of the complete data set ).

```{r}
#Group by genre and select the variables 'genre' and 'length'
film %>% 
  group_by(genre) %>%
  select(genre, length) %>%
  skim()
```

It is evident in from the summary table above that the length distribution is not equal amongst different film genres and therefore the missing film lengths will be handled by adding the median film length by genre to its corresponding missing columns (the mean is not used to avoid outlier influence). The different behaviour between genre and film length was expected, especially because one category is called "Short".

```{r}
#Median length of each genre
film.median <- film %>%
  group_by(genre) %>%
  select(genre, length) %>%
  summarise(median.length = median(length, na.rm=TRUE))
film.median
```

```{r}
#Input corresponding genre median for length missing values 
film <- film %>%
  inner_join(film.median,by=join_by(genre)) %>%
  mutate(length=ifelse(is.na(length),median.length,length)) %>%
  select(-median.length) 
```

```{r}
set.seed(123)
train_index <- createDataPartition(film$target, p = 0.8, list = FALSE)

film_train <- film[train_index, ]
film_test <- film[-train_index, ]

```

## Exploratory Analysis

The last step before fitting the Logistic Regression model is analysing the data set to identify possible patterns.

```{r}
#These are just some simple plots. Please add more plots as necessary. 
#If a certain plot is needed in the power point presentation please write its code here. 
```

```{r}
#| echo: true
#| label: fig-boxplot_1
#| fig-cap: Boxplot of Year by Rating
#| fig-width: 8
#| fig-height: 5
#| fig-align: center

#Plot target variable against year covariate 
film %>% ggplot(aes(x=Rating, y=year, colour=Rating)) + 
  geom_boxplot() + 
  theme(legend.position="none") +
  labs(x="Rating", y="Year")
```

```{r}
#| echo: true
#| label: fig-boxplot_2
#| fig-cap: Boxplot of Length by Rating
#| fig-width: 8
#| fig-height: 5
#| fig-align: center

#Plot target variable against length covariate 
film %>% ggplot(aes(x=Rating, y=length, colour=Rating)) + 
  geom_boxplot() + 
  theme(legend.position="none") +
  labs(x="Rating", y="Length")
```

```{r}
#| echo: true
#| label: fig-boxplot_3
#| fig-cap: Boxplot of Budget by Rating
#| fig-width: 8
#| fig-height: 5
#| fig-align: center

#Plot target variable against budget covariate 
film %>% ggplot(aes(x=Rating, y=budget, colour=Rating)) + 
  geom_boxplot() + 
  theme(legend.position="none") +
  labs(x="Rating", y="Budget")
```

```{r}
#| echo: true
#| label: fig-boxplot_4
#| fig-cap: Boxplot of Votes by Rating
#| fig-width: 8
#| fig-height: 5
#| fig-align: center

#Plot target variable against votes covariate 
film %>% ggplot(aes(x=Rating, y=votes, colour=Rating)) + 
  geom_boxplot() + 
  theme(legend.position="none") +
  labs(x="Rating", y="Votes")
```

```{r}
#| echo: true
#| label: fig-barplot_1
#| fig-cap: Barplot of count by genre
#| fig-width: 8
#| fig-height: 5
#| fig-align: center

#Count by genre
film %>% 
  ggplot(aes(x=genre, colour=genre)) +
  geom_bar() +
  theme(legend.position="none") +
  labs(y="Count", x="Film genre")
```

```{r}
#| echo: true
#| label: fig-barplot_2
#| fig-cap: Proportion of films with rating >7 by genre
#| fig-width: 8
#| fig-height: 5
#| fig-align: center

#Proportion of films with rating >7 by genre
film %>% group_by(genre) %>% 
  summarise(prop = mean(target)) %>% 
  arrange() %>% 
  ggplot(aes(x=genre, y=prop, colour=genre)) +
  geom_col() +
  theme(legend.position="none") +
  labs(y="Proportion with rating > 7", x="Film genre")
```

## Model Fitting

```{r}

#Fit a full model with all possible covariates
model1_1 <- glm(target ~ year + length + budget + votes + genre , data = film_train, 
             family = binomial(link = "logit"))
#The length in 1_1 the NA value in length is replaced by median
model1_1 %>%
  summary()

```

$$ \widehat{y}_\mbox{Rating} = \widehat{\alpha} + \widehat{\beta}_{\mbox{Year}} \cdot{\mbox{Year}} + \widehat{\beta}_{\mbox{Length}} \cdot{\mbox{Length}} + \widehat{\beta}_{\mbox{Budget}} \cdot{\mbox{Budget}} + \widehat{\beta}_{\mbox{Votes}} \cdot{\mbox{Votes}} + \widehat{\beta}_{\mbox{Genre}} \cdot\mathbb{I}_{\mbox{Genre}}(x) $$

```{r}
#set a dataset without NA
film <- read.csv("dataset09.csv") %>% 
  mutate(target = ifelse(rating>7, 1, 0)) %>%  #Define target variable
  mutate(Rating = ifelse(rating>7, ">7", "<=7"))  #Define Rating variable help us get better data visualisation
film_without<- na.omit(film)

#The length in 1_2 the NA value in length is removed
model1_2 <- glm(target ~ year + length + budget + votes + genre , data = film_train, 
             family = binomial(link = "logit"))
model1_2 %>%
  summary()
```

```{r}
summ(model1_1)
summ(model1_2)
```

```{r}
mod1_1coefs <- round(coef(model1_1), 3)
mod1_1coefs

confint(model1_1) %>%
  kable()
```

```{r}
mod1_2coefs <- round(coef(model1_2), 3)
mod1_2coefs

confint(model1_2) %>%
  kable()
```

The two treatments of length have slightly different impacts on the film.

```{r}
#Fit without categorical variable:genre, change votes to thousands so the scale is easier to interpret
model2 <- glm(target ~ year +length + budget + votes , data = film_train %>%
                mutate(votes=votes/1000), family = binomial(link = "logit"))
model2 %>%
  summary()
```

$$ \widehat{y}_\mbox{Rating} = \widehat{\alpha} + \widehat{\beta}_{\mbox{Year}} \cdot{\mbox{Year}} + \widehat{\beta}_{\mbox{Length}} \cdot{\mbox{Length}} + \widehat{\beta}_{\mbox{Budget}} \cdot{\mbox{Budget}} + \widehat{\beta}_{\mbox{Votes}} \cdot{\mbox{Votes}} $$

```{r}
summ(model2)
```

```{r}
mod2coefs <- round(coef(model2), 3)
mod2coefs
```

```{r}
confint(model2) %>%
  kable()
```

## Models Comparison

```{r}
#AIC
aic_values <- c(AIC(model1_1), AIC(model1_2), AIC(model2))
models_aic <- data.frame(Model = c("model1_1", "model1_2", "model2"),
                         AIC = aic_values)

print(models_aic)
```

```{r}
pred_prob_model1_1 <- predict(model1_1, newdata = film_test, type = "response")
y1_1_true <- film_test$target

pred_prob_model1_2 <- predict(model1_2, newdata = film_test, type = "response")
y1_2_true <- film_test$target

pred_prob_model2 <- predict(model2, newdata = film_test, type = "response")
y2_true <- film_test$target
```

```{r}
#ROC plots
roc_curve <- roc(y1_1_true, pred_prob_model1_1)
plot(roc_curve, main = "ROC Curve for Model1_1", col = "blue")
abline(a = 0, b = 1, lty = 2, col = "red")
auc_value <- round(auc(roc_curve), 2)
legend("bottomright", legend = paste("AUC =", auc_value), col = "blue", lty = 1, bty = "n")

```

```{r}
roc_curve <- roc(y1_2_true, pred_prob_model1_2)
plot(roc_curve, main = "ROC Curve for Model1_2", col = "blue")
abline(a = 0, b = 1, lty = 2, col = "red")
auc_value <- round(auc(roc_curve), 2)
legend("bottomright", legend = paste("AUC =", auc_value), col = "blue", lty = 1, bty = "n")
```

```{r}
roc_curve <- roc(y2_true, pred_prob_model2)
plot(roc_curve, main = "ROC Curve for Model2", col = "blue")
abline(a = 0, b = 1, lty = 2, col = "red")
auc_value <- round(auc(roc_curve), 2)
legend("bottomright", legend = paste("AUC =", auc_value), col = "blue", lty = 1, bty = "n")
```

```{r}
# Compute confusion matrix for each model
y_pred_model1_1 <- factor(ifelse(pred_prob_model1_1 > 0.5, 1, 0), levels = c(0, 1))
y1_1_true <- factor(y1_1_true, levels = c(0, 1))
conf_matrix_model1_1 <- confusionMatrix(y_pred_model1_1, y1_1_true)
print(conf_matrix_model1_1)
```

```{r}
y_pred_model1_2 <- factor(ifelse(pred_prob_model1_2 > 0.5, 1, 0), levels = c(0, 1))
y1_2_true <- factor(y1_2_true, levels = c(0, 1))
conf_matrix_model1_2 <- confusionMatrix(y_pred_model1_2, y1_2_true)
print(conf_matrix_model1_2)
```

```{r}
y_pred_model2 <- factor(ifelse(pred_prob_model2 > 0.5, 1, 0), levels = c(0, 1))
y2_true <- factor(y2_true, levels = c(0, 1))
conf_matrix_model2 <- confusionMatrix(y_pred_model2, y2_true)
print(conf_matrix_model2)
```

```{r}
#I cant get conf_matrix,sorry
conf_matrix_data <- data.frame(
  Actual = as.factor(y1_1_true),
  Predicted = as.factor(y_pred_model1_1)
)

conf_matrix_table <- table(conf_matrix_data)

conf_matrix_plot <- ggplot(data = as.data.frame.table(conf_matrix_table), 
                           aes(x = Var1, y = Var2, fill = Freq)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "white", high = "blue") +
  labs(x = "Actual", y = "Predicted", fill = "Frequency") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

print(conf_matrix_plot)
```

```{r}
# Compute precision
precision_model1_1 <- conf_matrix_model1_1$byClass["Precision"]
precision_model1_2 <- conf_matrix_model1_2$byClass["Precision"]
precision_model2 <- conf_matrix_model2$byClass["Precision"]

# Compute recall
recall_model1_1 <- conf_matrix_model1_1$byClass["Recall"]
recall_model1_2 <- conf_matrix_model1_2$byClass["Recall"]
recall_model2 <- conf_matrix_model2$byClass["Recall"]

# Compute accuracy
accuracy_model1_1 <- conf_matrix_model1_1$overall["Accuracy"]
accuracy_model1_2 <- conf_matrix_model1_2$overall["Accuracy"]
accuracy_model2 <- conf_matrix_model2$overall["Accuracy"]

# Create a data frame to store the metrics
metrics <- data.frame(Model = c("Model 1_1", "Model 1_2", "Model 2"),
                      Precision = c(precision_model1_1, precision_model1_2, precision_model2),
                      Recall = c(recall_model1_1, recall_model1_2, recall_model2),
                      Accuracy = c(accuracy_model1_1, accuracy_model1_2, accuracy_model2))

# Print the metrics
print(metrics)
```

## Conclusion

```{r}
#Write a conclusion about which variables were non-significant, which were significant and how much they influence the probability of having a score >7
```
